#!/usr/bin/env bash
set -euo pipefail

# Ensure we are in repo root
cd "$(dirname "$0")/.."

pip install uv
uv pip install --system "./docframe[cpu]"
uv pip install --system ./ldaca_web_app/docworkspace
uv pip install --system ./ldaca_web_app/backend

# Prefetch the Sentence-Transformers model used by BERTopic by default.
# BERTopic defaults to "sentence-transformers/all-MiniLM-L6-v2" when no embedding_model is specified.
# Download into the jovyan cache so runtime does not require network access.
export HF_HOME=${HF_HOME:-/home/jovyan/.cache/huggingface}
export TRANSFORMERS_CACHE=${TRANSFORMERS_CACHE:-$HF_HOME/transformers}
export HF_DATASETS_CACHE=${HF_DATASETS_CACHE:-$HF_HOME/datasets}
export SENTENCE_TRANSFORMERS_HOME=${SENTENCE_TRANSFORMERS_HOME:-$HF_HOME/sentence_transformers}
mkdir -p "$TRANSFORMERS_CACHE" "$HF_DATASETS_CACHE" "$SENTENCE_TRANSFORMERS_HOME"

python - <<'PY'
import os
try:
  from sentence_transformers import SentenceTransformer
except Exception as e:
  print(f"[postBuild] sentence-transformers not available yet: {e}")
else:
  cache = os.environ.get("SENTENCE_TRANSFORMERS_HOME") or None
  print(f"[postBuild] Prefetching 'sentence-transformers/all-MiniLM-L6-v2' -> {cache}")
  SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", cache_folder=cache)
  print("[postBuild] Model prefetched.")

try:
  import nltk
  nltk.download("stopwords")
  nltk.download("punkt")
  nltk.download("punkt_tab")
except Exception as e:
  pass
PY

pushd ldaca_web_app/frontend
npm install
npm run build